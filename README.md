# Deceptive Attribute Finder (DAF)

Network intrusion detection (NID) is an essential element of cyber defense to protect valuable assets in networks. Artificial intelligence (AI) is replacing traditional rule-based detectors, and many AI-based NID systems have been introduced in recent years to deal with the increased amount, speed, and variety of attacks. However, we found it perplexing that almost all reported detection performances of AI-based methods are near-perfect in their experiments, whereas such performance is hardly achieved in real environments. 

We report that deceptive features exist in popular datasets for AI-based NID development. Deceptive features seem informative for detection within a single dataset but can cause performance degradation when a detector trained with the features is applied to network traffic from a more general population. We first introduce a new performance evaluation strategy based on bootstrapping with a dataset of datasets, denoted by $D^2$, which is used to choose test cases from a larger sample. We show that the existing AI-based intrusion detectors exhibit degraded performance using our performance evaluation method, compared to what has been reported previously in their respective experiment based on single datasets. Based on the new evaluation strategy, we propose an algorithm called the deceptive attribute finder to discover deceptive attributes from a given dataset. Furthermore, we demonstrate that the detection performance of AI-based detectors trained with single datasets can be improved significantly by removing such attributes from training compared to the cases of using all original attributes.
